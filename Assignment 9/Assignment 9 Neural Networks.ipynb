{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Neural Networks Practice</h1>\n",
    "\n",
    "<h3>About the data</h3>\n",
    "The data contains sonar signal data collected after they are bounced off two kinds of objects (underwater). The objects are either rocks or mines and the sonar signals are sent at 60 different frequencies. The value returned is then recorded. The goal of the exercise is to build a model that can figure out whether an object is a rock or a mine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<li>Dataset: 208 samples of sonar signals bounced off either a cylindrical metal cylinder (mine) or a cylinrical rock (rock)</li>\n",
    "<li>Train a model to distinguish between a rock and a mine</li>\n",
    "<li>We'll build a simple neural net classifier and then run grid search to improve the results</li>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Prep the model results report</h2>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "results_df = pd.DataFrame(np.zeros(shape=(3,8)))\n",
    "results_df.index=[1,2,3]\n",
    "results_df.columns = [\"description\",\"training accuracy\",\"testing accuracy\",\"precision\",\"recall\",\"f1_score\",\"AUC\",\"AP\"]\n",
    "results_df.index.rename(\"Model\",inplace=True)\n",
    "results_df.description = [\"SimpleNN_1\",\"SimpleNN_2\",\"NN_Grid_Search\"]\n",
    "results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Report the results here</h2>\n",
    "<li>Do this after you've run all the models</li>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Run your models below and then return to this cell to report your results\n",
    "results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Build the models below this cell</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Get the data</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import fetch_openml\n",
    "df = fetch_openml('sonar')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Split the data into training and testing</h2>\n",
    "<li>Set mines as 0 and rocks as 1</li>\n",
    "<li>split the data into 20% testing and 80% training</li>\n",
    "<li>x_train, y_train, x_test, y_test</li>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X,y = df['data'],df['target']\n",
    "df = X.assign(target=y)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Build a neural network</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<li>the output layer in the NN can have multiple values</li>\n",
    "<li>Use one hot encoding to build an output layer of two nodes (0 and 1)</li>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Converting the y values into numbers</h2>\n",
    "<li>In our regression example, we used 0 for rocks and 1 for mines\n",
    "<li>sklearn has a LabelEncoder that will replace text with numbered labels\n",
    "<li>Instead of a single output node, we'll use two output nodes. One for 0 and one for 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_labels = \n",
    "y_train_oh = np.zeros((len(y_train),2),dtype=\"int\")\n",
    "y_train_oh[np.arange(len(y_train)), y_train.to_numpy(dtype=\"int\")] = 1\n",
    "y_test_oh = np.zeros((len(y_test),2),dtype=\"int\")\n",
    "y_test_oh[np.arange(len(y_test)), y_test.to_numpy(dtype=\"int\")] = 1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Building a basic neural net</h1>\n",
    "<li>You need to decide:\n",
    "<ol>\n",
    "<li>Number of hidden layers\n",
    "<li>Number of nodes in each hidden layer\n",
    "<li>Number of nodes in the input layer\n",
    "<li>Number of nodes in the output layer\n",
    "<li>Number of training passes (epochs)\n",
    "<li>Activation function to use\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Brief explanation of Neural Net Parameters</h3>\n",
    "<li><b>solver</b>: sgd (stochastic gradient descent), lbfgs (limited memory Broyden–Fletcher–Goldfarb–Shanno algorithm), adam (stochastic gradient based optimizer)\n",
    "<li><b>activation</b>: logistic (sigmoid), tanh (hyperbolic tan function), relu (linear unit function). relu returns max(0,x) and works better on two class dependent variables (we don't want both returned\n",
    "<li><b>alpha</b>: L2 regularization term. Regularization is used to prevent overfitting by not using the exact loss (difference between predicted and actual) when adjusting the weights (in a neural network model). L2 adds the sum of the square of the weights modified by a lambda parameter to each delta\n",
    "<li><b>batch size</b>: Number of cases to use in one epoch. \n",
    "<li><b>momentum</b>: A number between 0 and 1 that accelerates a gradient descent (e.g., sigmoid) algorithm if it is moving in the right (consistent) direction\n",
    "<li><b>shuffle</b>: shuffle the samples in each iteration (the order in which they are presented will change\n",
    "<li><b>tol</b>: if the improvement is less than this, the algorithm stops\n",
    "<li><b>Learning rate</b> A hyper parameter that controls how much weights should be adjusted after each epoch</li>\n",
    "<ul>\n",
    "<li>Too low, the model will take a long time to converge (expensive GPU cost)\n",
    "<li>Too high, the model may never converge\n",
    "<li>Bit of guesswork goes into this (e.g., start low, slowly increase the rate, see how the loss changes (loss = prediction error), and adjust the rate accordingly\n",
    "    <li>Setting it to constant is the default and the easiest place to start</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Basic NN model</h3>\n",
    "<li>See <a href=\"https://scikit-learn.org/stable/modules/generated/sklearn.neural_network.MLPClassifier.html\">https://scikit-learn.org/stable/modules/generated/sklearn.neural_network.MLPClassifier.html</a></li>\n",
    "<li>We'll start with one hidden layer of 60 nodes (1-1 correspondence with the input layer)\n",
    "<li>Use lbfgs as the solver</li>\n",
    "<li>An alpha of 0.00001</li>\n",
    "<li>Epochs (the max_iter parameter) set to 500</li>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "model = MLPClassifier(solver='lbfgs', alpha=1e-5,hidden_layer_sizes=60, max_iter = 500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<h3>Training and testing</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fit the model\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Report results</h4>\n",
    "My results:\n",
    "<pre>\n",
    "Training accuracy:  1.0\n",
    "Testing  accuracy:  0.5476190476190477\n",
    "precision:  0.5571428571428572\n",
    "recall:  0.5476190476190477\n",
    "f1 score:  0.5515348996741553\n",
    "auc 0.6996527777777777\n",
    "ap 0.6590433731528633\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix,f1_score,precision_score,recall_score\n",
    "from sklearn.metrics import roc_auc_score,average_precision_score\n",
    "test_pred = \n",
    "accuracy_training =\n",
    "accuracy_testing =\n",
    "f1 = \n",
    "precision = \n",
    "recall = \n",
    "auc = \n",
    "\n",
    "ap = \n",
    "\n",
    "print(\"Training accuracy: \",accuracy_training)\n",
    "print(\"Testing  accuracy: \",accuracy_testing)\n",
    "print(\"precision: \",precision)\n",
    "print(\"recall: \",recall)\n",
    "print(\"f1 score: \",f1)\n",
    "print(\"auc\",auc)\n",
    "print(\"ap\",ap)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df.loc[1,'training accuracy'] = accuracy_training\n",
    "results_df.loc[1,'testing accuracy'] = accuracy_testing\n",
    "\n",
    "results_df.loc[1,'precision'] = precision\n",
    "results_df.loc[1,'recall'] = recall\n",
    "results_df.loc[1,'f1_score'] = f1\n",
    "results_df.loc[1,\"AUC\"] = auc\n",
    "results_df.loc[1,\"AP\"] = ap\n",
    "results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Try a different set of parameters</h2>\n",
    "<li>More/fewer hidden layers?</li>\n",
    "<li>Change the number of nodes in hidden layers?</li>\n",
    "<li>Different solver?</li>\n",
    "<li>More iterations?</li>\n",
    "<li>Your choice! But do something different!</li>\n",
    "<li>Results could be worse, could be better, doesn't matter!</li>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df.loc[2,'training accuracy'] = accuracy_training\n",
    "results_df.loc[2,'testing accuracy'] = accuracy_testing\n",
    "\n",
    "results_df.loc[2,'precision'] = precision\n",
    "results_df.loc[2,'recall'] = recall\n",
    "results_df.loc[2,'f1_score'] = f1\n",
    "results_df.loc[2,\"AUC\"] = auc\n",
    "results_df.loc[2,\"AP\"] = ap\n",
    "results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Grid search</h2>\n",
    "<li>Use grid search to find a better NN model</li>\n",
    "<li>Note that this is open-ended. Use as many or as few values as you like</li>\n",
    "<li>My version has 1,134 combinations and ran for about 30 minutes so you may want to cut the number down to less than 300 combinations</li>\n",
    "<li>Refer to the documentation for help</li>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "parameters = {\n",
    "    'learning_rate':,\n",
    "    'batch_size' : ,\n",
    "    'solver' :,\n",
    "    'activation': ,\n",
    "    'alpha' : ,\n",
    "    'hidden_layer_sizes': \n",
    "}\n",
    "\n",
    "gs = GridSearchCV(estimator = MLPClassifier(random_state=42,max_iter=2000), param_grid=parameters,cv=3)\n",
    "gs.fit(X_train, y_train_oh)\n",
    "print(gs.best_score_)\n",
    "print(gs.best_params_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Get the best estimator and apply it</h2>\n",
    "<li>Doesn't matter what you get but it must have better scores than the two previous models!</li>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#clf = MLPClassifier(solver='adam', hidden_layer_sizes=(30,), max_iter = 2000, \n",
    "#                    activation='logistic',\n",
    "#                    learning_rate='invscaling')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "model = \n",
    "\n",
    "\n",
    "model.fit(X_train,y_train_oh)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Get the metrics and update results_df</h2>\n",
    "<b>Then, go to the top of the notebook and answer the question!</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df.loc[3,'training accuracy'] = accuracy_training\n",
    "results_df.loc[3,'testing accuracy'] = accuracy_testing\n",
    "\n",
    "results_df.loc[3,'precision'] = precision\n",
    "results_df.loc[3,'recall'] = recall\n",
    "results_df.loc[3,'f1_score'] = f1\n",
    "results_df.loc[3,\"AUC\"] = auc\n",
    "results_df.loc[3,\"AP\"] = ap\n",
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
